{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'update_train_log' from 'logger' (C:\\Users\\PAULOCESARCalabria\\Anaconda3\\envs\\PAULOCESARCalabriaEnv\\lib\\site-packages\\logger\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-34e7ea3d4673>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#from logger import update_predict_log, update_train_log\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mlogger\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mupdate_train_log\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'update_train_log' from 'logger' (C:\\Users\\PAULOCESARCalabria\\Anaconda3\\envs\\PAULOCESARCalabriaEnv\\lib\\site-packages\\logger\\__init__.py)"
     ]
    }
   ],
   "source": [
    "#from logger import update_predict_log, update_train_log\n",
    "from logger import update_train_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: logger in c:\\users\\paulocesarcalabria\\anaconda3\\envs\\paulocesarcalabriaenv\\lib\\site-packages (1.4)\n"
     ]
    }
   ],
   "source": [
    "#!pip install joblib\n",
    "#!pip install sklearn\n",
    "!pip install logger\n",
    "import time,os,re,csv,sys,uuid,joblib\n",
    "from datetime import date\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "#from logger import update_predict_log, update_train_log\n",
    "from cslib import fetch_ts, engineer_features\n",
    "\n",
    "## model specific variables (iterate the version and note with each change)\n",
    "MODEL_DIR = \"models\"\n",
    "MODEL_VERSION = 0.1\n",
    "MODEL_VERSION_NOTE = \"supervised learing model for time-series\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... loading ts data from files\n"
     ]
    }
   ],
   "source": [
    "data_dir = os.path.join(\"cs-train\")\n",
    "\n",
    "ts_all = fetch_ts(data_dir,clean=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y,dates = engineer_features(ts_all['all'])\n",
    "        \n",
    "## Perform a train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_data(data_dir):\n",
    "    \"\"\"\n",
    "    laod all json formatted files into a dataframe\n",
    "    \"\"\"\n",
    "\n",
    "    ## input testing\n",
    "    if not os.path.isdir(data_dir):\n",
    "        raise Exception(\"specified data dir does not exist\")\n",
    "    if not len(os.listdir(data_dir)) > 0:\n",
    "        raise Exception(\"specified data dir does not contain any files\")\n",
    "\n",
    "    file_list = [os.path.join(data_dir,f) for f in os.listdir(data_dir) if re.search(\"\\.json\",f)]\n",
    "    correct_columns = ['country', 'customer_id', 'day', 'invoice', 'month',\n",
    "                       'price', 'stream_id', 'times_viewed', 'year']\n",
    "\n",
    "    ## read data into a temp structure\n",
    "    all_months = {}\n",
    "    for file_name in file_list:\n",
    "        df = pd.read_json(file_name)\n",
    "        all_months[os.path.split(file_name)[-1]] = df\n",
    "\n",
    "    ## ensure the data are formatted with correct columns\n",
    "    for f,df in all_months.items():\n",
    "        cols = set(df.columns.tolist())\n",
    "        if 'StreamID' in cols:\n",
    "             df.rename(columns={'StreamID':'stream_id'},inplace=True)\n",
    "        if 'TimesViewed' in cols:\n",
    "            df.rename(columns={'TimesViewed':'times_viewed'},inplace=True)\n",
    "        if 'total_price' in cols:\n",
    "            df.rename(columns={'total_price':'price'},inplace=True)\n",
    "\n",
    "        cols = df.columns.tolist()\n",
    "        if sorted(cols) != correct_columns:\n",
    "            raise Exception(\"columns name could not be matched to correct cols\")\n",
    "\n",
    "    ## concat all of the data\n",
    "    df = pd.concat(list(all_months.values()),sort=True)\n",
    "    years,months,days = df['year'].values,df['month'].values,df['day'].values \n",
    "    dates = [\"{}-{}-{}\".format(years[i],str(months[i]).zfill(2),str(days[i]).zfill(2)) for i in range(df.shape[0])]\n",
    "    df['invoice_date'] = np.array(dates,dtype='datetime64[D]')\n",
    "    df['invoice'] = [re.sub(\"\\D+\",\"\",i) for i in df['invoice'].values]\n",
    "    \n",
    "    ## sort by date and reset the index\n",
    "    df.sort_values(by='invoice_date',inplace=True)\n",
    "    df.reset_index(drop=True,inplace=True)\n",
    "    \n",
    "    return(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>day</th>\n",
       "      <th>invoice</th>\n",
       "      <th>month</th>\n",
       "      <th>price</th>\n",
       "      <th>stream_id</th>\n",
       "      <th>times_viewed</th>\n",
       "      <th>year</th>\n",
       "      <th>invoice_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>13085.0</td>\n",
       "      <td>28</td>\n",
       "      <td>489434</td>\n",
       "      <td>11</td>\n",
       "      <td>6.95</td>\n",
       "      <td>85048</td>\n",
       "      <td>12</td>\n",
       "      <td>2017</td>\n",
       "      <td>2017-11-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>13085.0</td>\n",
       "      <td>28</td>\n",
       "      <td>489434</td>\n",
       "      <td>11</td>\n",
       "      <td>6.75</td>\n",
       "      <td>79323W</td>\n",
       "      <td>12</td>\n",
       "      <td>2017</td>\n",
       "      <td>2017-11-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>13085.0</td>\n",
       "      <td>28</td>\n",
       "      <td>489434</td>\n",
       "      <td>11</td>\n",
       "      <td>2.10</td>\n",
       "      <td>22041</td>\n",
       "      <td>21</td>\n",
       "      <td>2017</td>\n",
       "      <td>2017-11-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>13085.0</td>\n",
       "      <td>28</td>\n",
       "      <td>489434</td>\n",
       "      <td>11</td>\n",
       "      <td>1.25</td>\n",
       "      <td>21232</td>\n",
       "      <td>5</td>\n",
       "      <td>2017</td>\n",
       "      <td>2017-11-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>13085.0</td>\n",
       "      <td>28</td>\n",
       "      <td>489434</td>\n",
       "      <td>11</td>\n",
       "      <td>1.65</td>\n",
       "      <td>22064</td>\n",
       "      <td>17</td>\n",
       "      <td>2017</td>\n",
       "      <td>2017-11-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>815006</th>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>16098.0</td>\n",
       "      <td>31</td>\n",
       "      <td>562271</td>\n",
       "      <td>7</td>\n",
       "      <td>3.75</td>\n",
       "      <td>22725</td>\n",
       "      <td>2</td>\n",
       "      <td>2019</td>\n",
       "      <td>2019-07-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>815007</th>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>16098.0</td>\n",
       "      <td>31</td>\n",
       "      <td>562271</td>\n",
       "      <td>7</td>\n",
       "      <td>3.75</td>\n",
       "      <td>22726</td>\n",
       "      <td>12</td>\n",
       "      <td>2019</td>\n",
       "      <td>2019-07-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>815008</th>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>16098.0</td>\n",
       "      <td>31</td>\n",
       "      <td>562271</td>\n",
       "      <td>7</td>\n",
       "      <td>3.75</td>\n",
       "      <td>22727</td>\n",
       "      <td>6</td>\n",
       "      <td>2019</td>\n",
       "      <td>2019-07-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>815009</th>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>14056.0</td>\n",
       "      <td>31</td>\n",
       "      <td>562269</td>\n",
       "      <td>7</td>\n",
       "      <td>2.95</td>\n",
       "      <td>22090</td>\n",
       "      <td>2</td>\n",
       "      <td>2019</td>\n",
       "      <td>2019-07-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>815010</th>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>15628.0</td>\n",
       "      <td>31</td>\n",
       "      <td>562163</td>\n",
       "      <td>7</td>\n",
       "      <td>1.65</td>\n",
       "      <td>22558</td>\n",
       "      <td>12</td>\n",
       "      <td>2019</td>\n",
       "      <td>2019-07-31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>815011 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               country  customer_id  day invoice  month  price stream_id  \\\n",
       "0       United Kingdom      13085.0   28  489434     11   6.95     85048   \n",
       "1       United Kingdom      13085.0   28  489434     11   6.75    79323W   \n",
       "2       United Kingdom      13085.0   28  489434     11   2.10     22041   \n",
       "3       United Kingdom      13085.0   28  489434     11   1.25     21232   \n",
       "4       United Kingdom      13085.0   28  489434     11   1.65     22064   \n",
       "...                ...          ...  ...     ...    ...    ...       ...   \n",
       "815006  United Kingdom      16098.0   31  562271      7   3.75     22725   \n",
       "815007  United Kingdom      16098.0   31  562271      7   3.75     22726   \n",
       "815008  United Kingdom      16098.0   31  562271      7   3.75     22727   \n",
       "815009  United Kingdom      14056.0   31  562269      7   2.95     22090   \n",
       "815010  United Kingdom      15628.0   31  562163      7   1.65     22558   \n",
       "\n",
       "        times_viewed  year invoice_date  \n",
       "0                 12  2017   2017-11-28  \n",
       "1                 12  2017   2017-11-28  \n",
       "2                 21  2017   2017-11-28  \n",
       "3                  5  2017   2017-11-28  \n",
       "4                 17  2017   2017-11-28  \n",
       "...              ...   ...          ...  \n",
       "815006             2  2019   2019-07-31  \n",
       "815007            12  2019   2019-07-31  \n",
       "815008             6  2019   2019-07-31  \n",
       "815009             2  2019   2019-07-31  \n",
       "815010            12  2019   2019-07-31  \n",
       "\n",
       "[815011 rows x 10 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dir = os.path.join(\"cs-train\")\n",
    "df = fetch_data(data_dir)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## model specific variables (iterate the version and note with each change)\n",
    "MODEL_DIR = \"models\"\n",
    "MODEL_VERSION = 0.1\n",
    "MODEL_VERSION_NOTE = \"supervised learing model for time-series\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _model_train(df,tag,test=False):\n",
    "    \"\"\"\n",
    "    example funtion to train model\n",
    "    \n",
    "    The 'test' flag when set to 'True':\n",
    "        (1) subsets the data and serializes a test version\n",
    "        (2) specifies that the use of the 'test' log file \n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    ## start timer for runtime\n",
    "    time_start = time.time()\n",
    "    \n",
    "    X,y,dates = engineer_features(df)\n",
    "\n",
    "    if test:\n",
    "        n_samples = int(np.round(0.3 * X.shape[0]))\n",
    "        subset_indices = np.random.choice(np.arange(X.shape[0]),n_samples,\n",
    "                                          replace=False).astype(int)\n",
    "        mask = np.in1d(np.arange(y.size),subset_indices)\n",
    "        y=y[mask]\n",
    "        X=X[mask]\n",
    "        dates=dates[mask]\n",
    "        \n",
    "    ## Perform a train-test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25,\n",
    "                                                        shuffle=True, random_state=42)\n",
    "    ## train a random forest model\n",
    "    param_grid_rf = {\n",
    "    'rf__criterion': ['mse','mae'],\n",
    "    'rf__n_estimators': [10,15,20,25]\n",
    "    }\n",
    "\n",
    "    pipe_rf = Pipeline(steps=[('scaler', StandardScaler()),\n",
    "                              ('rf', RandomForestRegressor())])\n",
    "    \n",
    "    grid = GridSearchCV(pipe_rf, param_grid=param_grid_rf, cv=5, iid=False, n_jobs=-1)\n",
    "    grid.fit(X_train, y_train)\n",
    "    y_pred = grid.predict(X_test)\n",
    "    eval_rmse =  round(np.sqrt(mean_squared_error(y_test,y_pred)))\n",
    "    \n",
    "    ## retrain using all data\n",
    "    grid.fit(X, y)\n",
    "    model_name = re.sub(\"\\.\",\"_\",str(MODEL_VERSION))\n",
    "    if test:\n",
    "        saved_model = os.path.join(MODEL_DIR,\n",
    "                                   \"test-{}-{}.joblib\".format(tag,model_name))\n",
    "        print(\"... saving test version of model: {}\".format(saved_model))\n",
    "    else:\n",
    "        saved_model = os.path.join(MODEL_DIR,\n",
    "                                   \"sl-{}-{}.joblib\".format(tag,model_name))\n",
    "        print(\"... saving model: {}\".format(saved_model))\n",
    "        \n",
    "    joblib.dump(grid,saved_model)\n",
    "\n",
    "    m, s = divmod(time.time()-time_start, 60)\n",
    "    h, m = divmod(m, 60)\n",
    "    runtime = \"%03d:%02d:%02d\"%(h, m, s)\n",
    "\n",
    "    ## update log\n",
    "#    update_train_log(tag,(str(dates[0]),str(dates[-1])),{'rmse':eval_rmse},runtime,\n",
    "#                     MODEL_VERSION, MODEL_VERSION_NOTE,test=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_train(data_dir,test=False):\n",
    "    \"\"\"\n",
    "    funtion to train model given a df\n",
    "    \n",
    "    'mode' -  can be used to subset data essentially simulating a train\n",
    "    \"\"\"\n",
    "    \n",
    "    if not os.path.isdir(MODEL_DIR):\n",
    "        os.mkdir(MODEL_DIR)\n",
    "\n",
    "    if test:\n",
    "        print(\"... test flag on\")\n",
    "        print(\"...... subseting data\")\n",
    "        print(\"...... subseting countries\")\n",
    "        \n",
    "    ## fetch time-series formatted data\n",
    "    ts_data = fetch_ts(data_dir)\n",
    "\n",
    "    ## train a different model for each data sets\n",
    "    for country,df in ts_data.items():\n",
    "        \n",
    "        if test and country not in ['all','united_kingdom']:\n",
    "            continue\n",
    "        \n",
    "        _model_train(df,country,test=test)\n",
    "        \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_load(prefix='sl',data_dir=None,training=True):\n",
    "    \"\"\"\n",
    "    example funtion to load model\n",
    "    \n",
    "    The prefix allows the loading of different models\n",
    "    \"\"\"\n",
    "\n",
    "    if not data_dir:\n",
    "#        data_dir = os.path.join(\"..\",\"data\",\"cs-train\")\n",
    "        data_dir = os.path.join(\"cs-train\")\n",
    "    \n",
    "    models = [f for f in os.listdir(os.path.join(\".\",\"models\")) if re.search(\"sl\",f)]\n",
    "\n",
    "    if len(models) == 0:\n",
    "        raise Exception(\"Models with prefix '{}' cannot be found did you train?\".format(prefix))\n",
    "\n",
    "    all_models = {}\n",
    "    for model in models:\n",
    "        all_models[re.split(\"-\",model)[1]] = joblib.load(os.path.join(\".\",\"models\",model))\n",
    "\n",
    "    ## load data\n",
    "    ts_data = fetch_ts(data_dir)\n",
    "    all_data = {}\n",
    "    for country, df in ts_data.items():\n",
    "        X,y,dates = engineer_features(df,training=training)\n",
    "        dates = np.array([str(d) for d in dates])\n",
    "        all_data[country] = {\"X\":X,\"y\":y,\"dates\": dates}\n",
    "        \n",
    "    return(all_data, all_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_predict(country,year,month,day,all_models=None,test=False):\n",
    "    \"\"\"\n",
    "    example funtion to predict from model\n",
    "    \"\"\"\n",
    "\n",
    "    ## start timer for runtime\n",
    "    time_start = time.time()\n",
    "\n",
    "    ## load model if needed\n",
    "    if not all_models:\n",
    "        all_data,all_models = model_load(training=False)\n",
    "    \n",
    "    ## input checks\n",
    "    if country not in all_models.keys():\n",
    "        raise Exception(\"ERROR (model_predict) - model for country '{}' could not be found\".format(country))\n",
    "\n",
    "    for d in [year,month,day]:\n",
    "        if re.search(\"\\D\",d):\n",
    "            raise Exception(\"ERROR (model_predict) - invalid year, month or day\")\n",
    "    \n",
    "    ## load data\n",
    "    model = all_models[country]\n",
    "    data = all_data[country]\n",
    "\n",
    "    ## check date\n",
    "    target_date = \"{}-{}-{}\".format(year,str(month).zfill(2),str(day).zfill(2))\n",
    "    print(target_date)\n",
    "\n",
    "    if target_date not in data['dates']:\n",
    "        raise Exception(\"ERROR (model_predict) - date {} not in range {}-{}\".format(target_date,\n",
    "                                                                                    data['dates'][0],\n",
    "                                                                                    data['dates'][-1]))\n",
    "    date_indx = np.where(data['dates'] == target_date)[0][0]\n",
    "    query = data['X'].iloc[[date_indx]]\n",
    "    \n",
    "    ## sainty check\n",
    "    if data['dates'].shape[0] != data['X'].shape[0]:\n",
    "        raise Exception(\"ERROR (model_predict) - dimensions mismatch\")\n",
    "\n",
    "    ## make prediction and gather data for log entry\n",
    "    y_pred = model.predict(query)\n",
    "    y_proba = None\n",
    "    if 'predict_proba' in dir(model) and 'probability' in dir(model):\n",
    "        if model.probability == True:\n",
    "            y_proba = model.predict_proba(query)\n",
    "\n",
    "\n",
    "    m, s = divmod(time.time()-time_start, 60)\n",
    "    h, m = divmod(m, 60)\n",
    "    runtime = \"%03d:%02d:%02d\"%(h, m, s)\n",
    "\n",
    "    ## update predict log\n",
    "#    update_predict_log(country,y_pred,y_proba,target_date,\n",
    "#                       runtime, MODEL_VERSION, test=test)\n",
    "    \n",
    "    return({'y_pred':y_pred,'y_proba':y_proba})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING MODELS\n",
      "... test flag on\n",
      "...... subseting data\n",
      "...... subseting countries\n",
      "... loading ts data from files\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'iid'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-da7eb80377f4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;31m#    data_dir = os.path.join(\"..\",\"data\",\"cs-train\")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mdata_dir\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"cs-train\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     \u001b[0mmodel_train\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[1;31m## load the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-21-f68f1e0f9812>\u001b[0m in \u001b[0;36mmodel_train\u001b[1;34m(data_dir, test)\u001b[0m\n\u001b[0;32m     23\u001b[0m             \u001b[1;32mcontinue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m         \u001b[0m_model_train\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcountry\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m     \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-18-29cf31856b8d>\u001b[0m in \u001b[0;36m_model_train\u001b[1;34m(df, tag, test)\u001b[0m\n\u001b[0;32m     35\u001b[0m                               ('rf', RandomForestRegressor())])\n\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m     \u001b[0mgrid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpipe_rf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparam_grid_rf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miid\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m     \u001b[0mgrid\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgrid\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\PAULOCESARCalabriaEnv\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'iid'"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "\n",
    "    \"\"\"\n",
    "    basic test procedure for model.py\n",
    "    \"\"\"\n",
    "\n",
    "    ## train the model\n",
    "    print(\"TRAINING MODELS\")\n",
    "#    data_dir = os.path.join(\"..\",\"data\",\"cs-train\")\n",
    "    data_dir = os.path.join(\"cs-train\")\n",
    "    model_train(data_dir,test=True)\n",
    "\n",
    "    ## load the model\n",
    "    print(\"LOADING MODELS\")\n",
    "    all_data, all_models = model_load()\n",
    "    print(\"... models loaded: \",\",\".join(all_models.keys()))\n",
    "\n",
    "    ## test predict\n",
    "    country='all'\n",
    "    year='2018'\n",
    "    month='01'\n",
    "    day='05'\n",
    "    result = model_predict(country,year,month,day)\n",
    "    print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:PAULOCESARCalabriaEnv] *",
   "language": "python",
   "name": "conda-env-PAULOCESARCalabriaEnv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
